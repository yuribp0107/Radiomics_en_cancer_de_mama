{"cells":[{"cell_type":"markdown","metadata":{"id":"491c06b0-fdb9-4ab3-a9cf-31f139b5ad1d"},"source":["#**Preparacion del entorno**"]},{"cell_type":"markdown","metadata":{"id":"XENngmn1bz_1"},"source":["## **Instalacion de librerias**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KySJWNLa2IP"},"outputs":[],"source":["# Bibliotecas básicas que se usan en el experimento\n","import pandas as pd\n","import random\n","import numpy as np\n","import time\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline\n","\n","#imblearn, de clase desequilibrada,\n","!pip install -U imbalanced-learn\n","from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE,SVMSMOTE, ADASYN #in the case of this experiment, no use kmeanssmote\n","\n","#Liberia sklearn \n","from sklearn.impute import SimpleImputer # Univariate imputer for completing missing values with simple strategies.\n","from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, RandomizedSearchCV #defines the data partitioning and cross validation strategy. In this experiment use GridsearhCV\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler #In this expermiento, is used StandardScaler\n","from sklearn.pipeline import Pipeline\n","\n","#Metodos de seleccion de caracteristicas\n","from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif, GenericUnivariateSelect, VarianceThreshold, SequentialFeatureSelector, RFE, SelectFromModel, RFECV #In this expermiento, is used SelectKBest with f_classif and mutual_info_classif\n","!pip install skfeature-chappers\n","from skfeature.function.similarity_based import fisher_score, SPEC, lap_score, reliefF, trace_ratio # https://jundongl.github.io/scikit-feature/html/skfeature.function.html\n","from skfeature.function.information_theoretical_based import CIFE, CMIM, MRMR, MIM, JMI\n","from skfeature.function.statistical_based import t_score, gini_index, chi_square, f_score, low_variance\n","from scipy.stats import wilcoxon #This function is used in the feature selection method, according to the Wilcoxon criteria.\n","!pip install Boruta\n","from boruta import BorutaPy\n","\n","# clasificadores\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import LinearSVC, NuSVC, SVC\n","from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF,DotProduct,Matern,RationalQuadratic,WhiteKernel\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","#metricas\n","from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,confusion_matrix,roc_auc_score, classification_report\n","\n","#Guardar el dataframe y la serie en google DRIVE\n","from google.colab import drive, files, auth\n","from google.auth import default\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"myanEm7wDiAL"},"source":["##**Funciones**"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los hiperparametros RL, BI, MVS, PMC, PG, ADL**"],"metadata":{"id":"kOEZ1btk9MnI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWqkRbcVdB0r"},"outputs":[],"source":["def RL_BI_MVS_PMC_PG_ADL():\n","  #Selection molecular subtype and hormone receptor\n","  problemas_elegidos = [\"luminal_A\",\"luminal_B\",\"her2\",\"triple_negativo\"]\n","  \n","  numeración_clasificadores = {\n","                      \"1\":\"LR\", \n","                      \"2\":\"BI\", \n","                      \"3\":\"MVS\", \n","                      \"4\":\"PMC\",\n","                      \"5\":\"PG\",\n","                      \"7\":\"ADL\"}\n","  print(numeración_clasificadores) \n","  clasificador = numeración_clasificadores[input(\"ndique el valor del modelo de clasificación: \")]\n","\n","  #hiperparametros de los clasificadores\n","  hiperparámetros_ = {\n","      \"RL\" : {\"C\":(list(np.logspace(-4, 4, 20))),\n","              \"penalty\":[\"l1\",\"l2\",\"none\"],\n","              \"solver\" : ['lbfgs', 'liblinear']}, \n","      \"BI\" : {'var_smoothing': np.logspace(11,-11, num=1000)}, \n","      \"MSV\" : {'C':np.logspace(-6, 6, 13, base = 2.0),\n","               \"gamma\":[\"auto\"], \"probability\" : [True]},\n","      \"PMC\": {\n","          \"hidden_layer_sizes\": [(8, 16, 32), (8, 16, 32)], \n","          \"max_iter\" :[1000]},\n","      \"PG\": {\"n_restarts_optimizer\" : np.arange(1, 11)},\n","      \"ADL\": {'shrinkage': [None,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,'auto'],\n","              'n_components': [None] + [1, 2, 5, 8, 13, 21, 34, 55]}  \n","      }\n","  hiperparámetros = hiperparámetros_[clasificador]\n","\n","  #ramdom_state\n","  Random_State = [0,42,50,60,90] \n","\n","   #Metodo_de_seleccion_de_características\n","  fsel = ['_IMC_', '_MIM_', '_IG_', '_MF_', '_IM_', '_RELF_', '_MRMR_', 'PT', 'PW', 'PF']\n","  \n","  #numero de caracteristicas seleccionadas\n","  n_caracteristicas = [1,2,4,8,16,32]\n","\n","\n","  return problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los hiperparametros WMC, BA, EA, AD**"],"metadata":{"id":"rC2SeIcdfzpJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7whvKu6Mm8Ox"},"outputs":[],"source":["def VMC_BA_EA_AD():\n","  #Seleccion del subtipo molecular\n","  problema_de_clasificacion = {\"0\":\"luminal_A\", \n","                        \"1\":\"luminal_B\",\n","                        \"2\":\"her2\",\n","                        \"3\":\"triple_negativo\",\n","}\n","  print(problema_de_clasificacion)\n","  problemas_elegidos = problema_de_clasificacion[input(\"Indique el valor del subtipo molecular: \")] \n","  \n","  #Clasificadores\n","  numeración_clasificadores = {\"1\":\"VMC\",\n","                      \"2\":\"BA\",\n","                      \"3\":\"EA\",\n","                      \"4\":\"AD\"}\n","  print(numeración_clasificadores) \n","  clasificador = numeración_clasificadores[input(\"ndique el valor del modelo de clasificación: \")]\n","\n","  #hiperparametros de los clasificadores\n","  hiperparámetros_ = {\n","      \"VMC\" : {\"n_neighbors\" : list(range(1, 500)),\n","               \"metric\": [\"euclidean\",\"manhattan\", \"minkowski\"]},\n","      \"BA\" : {\"n_estimators\": list(range(1,1000,50))},\n","      \"EA\" : {\"n_estimators\": list(range(1,1000,50))},\n","      \"AD\": {'max_depth': [10,30,50,70,100,300,500,700,1000,3000,5000,7000, None],\n","             'min_samples_split': [2,5,10,20,50,100],\n","             'min_samples_leaf':[2,5,10,20,50,100]},\n","      }\n","  hiperparámetros = hiperparámetros_[clasificador]\n"," \n","  #ramdom_state\n","  Random_State_ = {\"0\":0,\"42\":42, \"50\":50, \"60\":60, \"90\":90} #Será necesario tantas veces? . Este artículo habla de cómo 5 es suficiente. https://www.sciencedirect.com/science/article/pii/S0957417421013622?via%3Dihub#tbl1\n","  print(list(Random_State_.keys()))\n","  Random_State = Random_State_[input(\"Indique el valor del random state: \")] \n","\n","  #Metodo_de_seleccion_de_características\n","  fsel = ['_IMC_', '_MIM_', '_IG_', '_MF_', '_IM_', '_RELF_', '_MRMR_', 'PT', 'PW', 'PF']\n","  \n","  #numero de caracteristicas seleccionadas\n","  n_caracteristicas = [1,2,4,8,16,32]\n","\n","\n","  return problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas\n","\n"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los hiperparametros RA y RG**"],"metadata":{"id":"nze_oyzQf5wn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPNi0Uz8cNV7"},"outputs":[],"source":["def RA_RG():\n","  #Seleccion del subtipo molecular\n","  problema_de_clasificacion = {\"0\":\"luminal_A\", \n","                        \"1\":\"luminal_B\",\n","                        \"2\":\"her2\",\n","                        \"3\":\"triple_negativo\",\n","}\n","  print(problema_de_clasificacion)\n","  problemas_elegidos = problema_de_clasificacion[input(\"Indique el valor del subtipo molecular: \")] \n","  \n","  #Clasificadores\n","  numeración_clasificadores = {\"1\":\"RA\",\n","                      \"2\":\"RG\"}\n","  print(numeración_clasificadores) \n","  clasificador = numeración_clasificadores[input(\"ndique el valor del modelo de clasificación: \")]\n","\n","  #Hiperparametros \n","  hiperparámetros_ = {\n","      \"RA\" : {\"n_estimators\": list(range(1,1000,50)),\n","              'learning_rate':list(np.linspace(0.1, 2.0, 20, endpoint=True))},\n","      \"RG\": {\"n_estimators\": list(range(1,1000,50)),\n","              'learning_rate':list(np.linspace(0.1, 2.0, 20, endpoint=True))},\n","      }\n","  hiperparámetros = hiperparámetros_[clasificador]\n","  \n","  #ramdom_state\n","  Random_State_ = {\"0\":0,\"42\":42, \"50\":50, \"60\":60, \"90\":90} #Será necesario tantas veces? . Este artículo habla de cómo 5 es suficiente. https://www.sciencedirect.com/science/article/pii/S0957417421013622?via%3Dihub#tbl1\n","  print(list(Random_State_.keys()))\n","  Random_State = Random_State_[input(\"Indique el valor del random state: \")] \n","\n","   #Metodo_de_seleccion_de_características\n","  Metodo_de_seleccion_de_características = { \"1\":\"_IMC_\",\n","                                      \"2\":\"_MIM_\",\n","                                      \"3\":\"_IG_\",\n","                                      \"4\":\"_MF_\",\n","                                      \"5\":\"_IM_\",\n","                                      \"6\": \"_RELF_\",\n","                                      \"7\": \"_MRMR_\",\n","                                      \"8\": \"_PT_\",\n","                                      \"9\": \"_PW_\",\n","                                      \"10\":\"_PF_\"\n","                                  }\n","  print(Metodo_de_seleccion_de_características)\n","  fsel = Metodo_de_seleccion_de_características[input(\"Indique el valor del método de selección de características:\")]\n","  \n","  #numero de caracteristicas seleccionadas\n","  n_caracteristicas = [1,2,4,8,16,32]\n","\n","  return problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas"]},{"cell_type":"markdown","metadata":{"id":"LeuTNdzlbnig"},"source":["##**Gridsearch**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9uYZIWqTmTjd"},"outputs":[],"source":["#iterativo \n","def gridsearch_(problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas):\n","\n"," #Validador cruzado K-Fold estratificado repetido.\n","  CV =  RepeatedStratifiedKFold(n_splits = 10, n_repeats = 1, random_state = 42)\n","\n","  #clasificadores\n","  clasificadores = {\"VMC\" : KNeighborsClassifier(),\n","                    \"RL\" : LogisticRegression(),\n","                    \"BI\" : GaussianNB(),\n","                    \"MVS\" : SVC(),\n","                    \"BA\" : RandomForestClassifier(),\n","                    \"RA\" : AdaBoostClassifier(),\n","                    \"EA\" : ExtraTreesClassifier(),\n","                    \"AD\" : DecisionTreeClassifier(),\n","                    \"RG\" : GradientBoostingClassifier(),\n","                    \"PMC\" : MLPClassifier(),\n","                    \"PG\" : GaussianProcessClassifier(),\n","                    \"ADL\": LinearDiscriminantAnalysis()}\n","  \n","\n","  #Estimador\n","  estimador_base = clasificadores[clasificador]\n","  nombre_estimador = str(estimador_base).replace('()',  '', 1) \n","\n","  \n","  #Exportar el conjunto de datos preprocesados\n","  X_train_fs.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/X_train/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_X_train\"+fsel+str(n_caracteristicas)+\".csv\")\n","  X_train = X_train_fs_.drop([\"Unnamed: 0\"], axis = 1)\n","  y_train.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/y_train/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_y_train\"+fsel+str(n_caracteristicas)+\".csv\")\n","  y_train = y_train_.drop([\"Unnamed: 0\"], axis = 1)\n","  X_test_fs.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/X_test/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_X_test\"+fsel+str(n_caracteristicas)+\".csv\")\n","  X_test = X_test_fs_.drop([\"Unnamed: 0\"], axis = 1)\n","  y_test.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/y_test/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_y_test\"+fsel+str(n_caracteristicas)+\".csv\")\n","  y_test = y_test_.drop([\"Unnamed: 0\"], axis = 1)\n","  \n","\n","  #GridSearch\n","  start = time.time()  # Inicio del tiempo de ejecucion de la funcion GridSearchCV\n","  clf = GridSearchCV(base_estimator, param_grid= hyperparameters, cv = CV, n_jobs = -1, scoring='roc_auc').fit(X_train, y_train)\n","  end = time.time() # fin del tiempo de ejecucion de la funcion GridSearchCV\n","  times_clf = str(end - start) #times_clf, corresponde al tiempo de ejecución del método de selección de características\n","  roc_auc_train = clf.best_score_\n","  y_pred_1 = clf.predict(X_test)\n","  y_pred_2 = clf.predict_proba(X_test)[:, 1]\n","  best_estimator_gs = clf.best_estimator_\n","  best_params_gs = clf.best_params_\n","  \n","  #Puntuación del estimador\n","  roc_auc_test_1 = (roc_auc_score(y_test,y_pred_1))\n","  roc_auc_test_2 = (roc_auc_score(y_test,y_pred_2))\n","  f1_score_test_1 = (f1_score(y_test,y_pred_1))\n","  precision_score_test_1 = (precision_score(y_test,y_pred_1))\n","  recall_score_test_1 = (recall_score(y_test,y_pred_1))\n","  accuracy_score_test_1 = (accuracy_score(y_test,y_pred_1))\n","\n","  #nombre de índice del dataframe de datos\n","  column_ = (chosen_problems + \"_\"+ classifier +\"_gs_\"+ str(Random_State)+ fsel + str(n_caracteristicas))\n","  #dataframe\n","  df_gs_ = pd.Series({\n","               \"roc_train\": roc_auc_train,\n","                \"roc_test_1\": roc_auc_test_1, \n","                \"roc_test_2\": roc_auc_test_2,\n","                \"f1_test_1\":f1_score_test_1,\n","                \"precision_test_1\":precision_score_test_1,\n","                \"recall_test_1\":recall_score_test_1,\n","                \"accuracy_test_1\":accuracy_score_test_1,\n","                \"time_clf_gs\": times_clf,\n","                \"estimator\": best_estimator_gs}, name = column_ )\n","  df_gs_best_parameters =pd.Series(data = best_params_gs, name = column_)\n","  df_gs = pd.concat([df_gs_, df_gs_best_parameters])\n","\n","\n","  df_gs.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/clasificadores/\"+nombre_estimador+\"/\"+fsel+\"/_\"+str(Random_State)+\"/\"+problemas_elegidos +\"_\"+clasificador+\"_rs_\"+str(Random_State)+fsel+str(n_caracteristicas)+\".csv\")"]},{"cell_type":"markdown","metadata":{"id":"tqlsxu5cjwIT"},"source":["#**Aplicacion del experimento**"]},{"cell_type":"markdown","metadata":{"id":"7C0Y23K6ax_N"},"source":["##**RA and RG**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_lm6K3McohS"},"outputs":[],"source":["#selecciona los parametros de la funcion gridsearch\n","problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas = RA_RG()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJsLt3Lcjyi9"},"outputs":[],"source":["#ejecucion del experimento\n","for i in range(len(n_feature)):\n","  gridsearch_(problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas[i])"]},{"cell_type":"markdown","metadata":{"id":"j6x4nv2fmHbZ"},"source":["##**VMC ,BA ,EA y AD**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jy4Nn2_4nOp4"},"outputs":[],"source":["#selecciona los parametros de la funcion gridsearch\n","problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas = VMC_BA_EA_AD()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5ceeWLymHbm"},"outputs":[],"source":["#ejecucion del experimento\n","for x in range(len(fsel)):\n","  for i in range(len(n_feature)):\n","    gridsearch_(problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas[i])"]},{"cell_type":"markdown","metadata":{"id":"9XxMVET9o28g"},"source":["##**RL ,BI ,VMC ,PMC ,PG y ADL**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3r_YrlxmHbh"},"outputs":[],"source":["#selecciona los parametros de la funcion gridsearch\n","problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas = RL_BI_MVS_PMC_PG_ADL()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"P42wRXG1pIJj"},"outputs":[],"source":["#ejecucion del experimento\n","for z in range(4)):\n","  for x in range(10):\n","    for i in range(6):\n","      gridsearch_(problemas_elegidos,clasificador,hiperparámetros,Random_State,fsel,n_caracteristicas[i])"]}],"metadata":{"colab":{"collapsed_sections":["XENngmn1bz_1","myanEm7wDiAL","kOEZ1btk9MnI","rC2SeIcdfzpJ","nze_oyzQf5wn","LeuTNdzlbnig","tqlsxu5cjwIT","7C0Y23K6ax_N","j6x4nv2fmHbZ","9XxMVET9o28g"],"provenance":[{"file_id":"1eRsmi2-bUyHx_Rea0Y_nENaPcFFLzDC6","timestamp":1679510212672},{"file_id":"1JC4cIUld6VwqZRRzz6lvVK1hPIOmAp-X","timestamp":1679510177853},{"file_id":"1YI1V9HpznbThe0jpAhMRjiyczUN9x_UP","timestamp":1679510152718},{"file_id":"1U8104QuPn8JoBtprdRvyurbD5RQtzEm6","timestamp":1679510048490}],"authorship_tag":"ABX9TyMsjfZ78w/WxeGaIsDNtMAW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}