{"cells":[{"cell_type":"markdown","metadata":{"id":"2fcfb833-1697-4492-9f9a-663e11bd4160"},"source":["#**Preparacion del entorno**"]},{"cell_type":"markdown","metadata":{"id":"491c06b0-fdb9-4ab3-a9cf-31f139b5ad1d"},"source":["## **Instalacion de librerias**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wv0hUclJ1y2d"},"outputs":[],"source":["# Bibliotecas básicas que se usan en el experimento\n","import pandas as pd\n","import random\n","import numpy as np\n","import time\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline\n","\n","#imblearn, de clase desequilibrada,\n","!pip install -U imbalanced-learn\n","from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE,SVMSMOTE, ADASYN #in the case of this experiment, no use kmeanssmote\n","\n","#Liberia sklearn \n","from sklearn.impute import SimpleImputer # Univariate imputer for completing missing values with simple strategies.\n","from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, RandomizedSearchCV #defines the data partitioning and cross validation strategy. In this experiment use GridsearhCV\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler #In this expermiento, is used StandardScaler\n","from sklearn.pipeline import Pipeline\n","\n","#Metodos de seleccion de caracteristicas\n","from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif, GenericUnivariateSelect, VarianceThreshold, SequentialFeatureSelector, RFE, SelectFromModel, RFECV #In this expermiento, is used SelectKBest with f_classif and mutual_info_classif\n","!pip install skfeature-chappers\n","from skfeature.function.similarity_based import fisher_score, SPEC, lap_score, reliefF, trace_ratio # https://jundongl.github.io/scikit-feature/html/skfeature.function.html\n","from skfeature.function.information_theoretical_based import CIFE, CMIM, MRMR, MIM, JMI\n","from skfeature.function.statistical_based import t_score, gini_index, chi_square, f_score, low_variance\n","from scipy.stats import wilcoxon #This function is used in the feature selection method, according to the Wilcoxon criteria.\n","!pip install Boruta\n","from boruta import BorutaPy\n","\n","# clasificadores\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import LinearSVC, NuSVC, SVC\n","from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF,DotProduct,Matern,RationalQuadratic,WhiteKernel\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","#metricas\n","from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,confusion_matrix,roc_auc_score, classification_report\n","\n","#Guardar el dataframe y la serie en google DRIVE\n","from google.colab import drive, files, auth\n","from google.auth import default\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"WXEVbysu3wg4"},"source":["##### **Funcion de Wilcoxon**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9cKKamQh4IE"},"outputs":[],"source":["#método de selección de características tomado de github por Aydin demircioglu\n","#Link : https://github.com/aydindemircioglu/radFS/blob/main/extraFeatureSelections.py\n","def wilcoxon_score(X, y):\n","    \"\"\"\n","    This function calculates t_score for each feature, where t_score is only used for binary problem\n","    t_score = |mean1-mean2|/sqrt(((std1^2)/n1)+((std2^2)/n2)))\n","    Input\n","    -----\n","    X: {numpy array}, shape (n_samples, n_features)\n","        input data\n","    y: {numpy array}, shape (n_samples,)\n","        input class labels\n","    Output\n","    ------\n","    F: {numpy array}, shape (n_features,)\n","        t-score for each feature\n","    \"\"\"\n","\n","    n_samples, n_features = X.shape\n","    F = np.zeros(n_features)\n","    c = np.unique(y)\n","    if len(c) == 2:\n","        for i in range(n_features):\n","            st, p = wilcoxon(X[:, i], y, zero_method='wilcox', correction=False, alternative='two-sided', mode='auto')\n","            F[i] = 1 - p\n","    else:\n","        print('y should be guaranteed to a binary class vector')\n","        exit(0)\n","    return np.abs(F)\n","def feature_ranking(F):\n","    \"\"\"\n","    Rank features in descending order according to t-score, the higher the t-score, the more important the feature is\n","    \"\"\"\n","    idx = np.argsort(F)\n","    return idx[::-1]\n"]},{"cell_type":"markdown","metadata":{"id":"myanEm7wDiAL"},"source":["##**Funciones**"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los metodos MIM y IMC**"],"metadata":{"id":"kOEZ1btk9MnI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxODs36xxqF1"},"outputs":[],"source":["\n","def MIM_IMC():\n","  #Seleccion del subtipo molecular\n","  problema_de_clasificacion = {\"0\":\"luminal_A\", \n","                        \"1\":\"luminal_B\",\n","                        \"2\":\"her2\",\n","                        \"3\":\"triple_negativo\",\n","}\n","  print(problema_de_clasificacion)\n","  problemas_elegidos = problema_de_clasificacion[input(\"Indique el valor del subtipo molecular: \")] \n","  \n","\n","\n","  #Metodo_de_seleccion_de_características\n","  Metodo_de_seleccion_de_características = { \"1\":\"_IMC_\",\n","                                      \"2\":\"_MIM_\",\n","                                  }\n","  print(Metodo_de_seleccion_de_características)\n","  fsel = Metodo_de_seleccion_de_características[input(\"Indique el valor del método de selección de características:\")]\n","\n","  #ramdom_state\n","  Random_State_ = {\"0\":0,\"42\":42, \"50\":50, \"60\":60, \"90\":90} #Será necesario tantas veces? . Este artículo habla de cómo 5 es suficiente. https://www.sciencedirect.com/science/article/pii/S0957417421013622?via%3Dihub#tbl1\n","  print(list(Random_State_.keys()))\n","  Random_State = Random_State_[input(\"Indique el valor del random state: \")] \n","\n","  return problemas_elegidos,fsel,Random_State"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los metodos IG**"],"metadata":{"id":"LvovWkLYHPaq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5RJvcygsz5Vk"},"outputs":[],"source":["def IG():\n","  #Seleccion del subtipo molecular\n","  problema_de_clasificacion = {\"0\":\"luminal_A\", \n","                        \"1\":\"luminal_B\",\n","                        \"2\":\"her2\",\n","                        \"3\":\"triple_negativo\",\n","}\n","  print(problema_de_clasificacion)\n","  problemas_elegidos = problema_de_clasificacion[input(\"Indique el valor del subtipo molecular: \")] \n","  \n","\n","\n","  #Metodo_de_seleccion_de_características\n","  fsel = \"_IG_\"\n","  \n","  #ramdom_state\n","  Random_State = [0,42,50,60,90]\n","  \n","  return problemas_elegidos,fsel,Random_State"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los metodos IM,RELF y MRMR**"],"metadata":{"id":"DIqsmonxHkqK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2BcbJhQ7fGx6"},"outputs":[],"source":["def IM_RELF_MRMR():\n","  #Seleccion del subtipo molecular\n","  problema_de_clasificacion = {\"0\":\"luminal_A\", \n","                        \"1\":\"luminal_B\",\n","                        \"2\":\"her2\",\n","                        \"3\":\"triple_negativo\",\n","}\n","  print(problema_de_clasificacion)\n","  problemas_elegidos = problema_de_clasificacion[input(\"Indique el valor del subtipo molecular: \")] \n","  \n","  #Metodo_de_seleccion_de_características\n","  Metodo_de_seleccion_de_características = { \"1\":\"_IM_\",\n","                                      \"2\":\"RELF\",\n","                                      \"3\": \"_MRMR_\",\n","\n","                                  }\n","  print(Metodo_de_seleccion_de_características)\n","  fsel = Metodo_de_seleccion_de_características[input(\"Indique el valor del método de selección de características:\")]\n","\n","\n","  #ramdom_state\n","  Random_State = [0,42,50,60,90]\n","  \n","  return problemas_elegidos,fsel,Random_State"]},{"cell_type":"markdown","source":["#####**Funcion optimiza los metodos MF, PF,PT y PW**"],"metadata":{"id":"wCKh38yxHsSG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xscmzs5S0jka"},"outputs":[],"source":["def MF_PF_PT_PW():\n","\n","  #Seleccion del subtipo molecular\n","  problemas_elegidos = {\"0\":\"luminal_A\", \n","                        \"1\":\"luminal_B\",\n","                        \"2\":\"her2\",\n","                        \"3\":\"triple_negativo\",\n","}\n","\n","\n","  #Feature selection methods\n","  Feature_selection_methods = {\"1\":\"_f_score_\",\"2\":\"_Fisher_\", \"3\":\"_t_score_\",\"4\":\"_WLCX_\",\"5\":\"_LASSO_\"}\n","  print(Feature_selection_methods)\n","  fsel = Feature_selection_methods[input(\"Indicate the value of the feature selection method: \")]\n","\n","  #Metodo_de_seleccion_de_características\n","  Metodo_de_seleccion_de_características = { \"1\":\"_MF_\",\n","                                      \"2\":\"_PF_\",\n","                                      \"3\": \"_PT_\",\n","                                      \"4\": \"_PW_\",\n","                                  }\n","  print(Metodo_de_seleccion_de_características)\n","  fsel = Metodo_de_seleccion_de_características[input(\"Indique el valor del método de selección de características:\")]\n","\n","  #ramdom_state\n","  Random_State = [0,42,50,60,90]\n","\n","  \n","  return problemas_elegidos,fsel,Random_State"]},{"cell_type":"markdown","metadata":{"id":"EdLpMV0Aie7-"},"source":["####**Metodos de seleccion de caracteristicas**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTBl0lejlse4"},"outputs":[],"source":["def metodos_seleccion_caracteristicas(fsel, n_caracteristicas):\n"," #Este grupo de métodos de selección de funciones se basa en la biblioteca sklearn\n","  if fsel == \"_MF_\":\n","    fselector = SelectKBest( k = n_feature)\n","  elif fsel ==\"_IM_\":\n","    fselector = SelectKBest(mutual_info_classif, k = n_feature)\n","    \n","  ##Este grupo de métodos de selección de funciones se basa en la biblioteca skfeature \n","  elif fsel == \"_PF_\":\n","    def fisher_score_fct (X, y):\n","      scores = fisher_score.fisher_score (X,y)\n","      return scores\n","    fselector = SelectKBest(fisher_score_fct, k = n_feature)\n","  elif fsel == \"_ReliefF_\":\n","    def relieff_score_fct (X, y):\n","      scores = reliefF.reliefF (X,y)\n","      return scores\n","    fselector = SelectKBest(relieff_score_fct, k = n_feature)\n","  elif fsel == \"_IG_\":\n","    def gini_index_fct (X, y):\n","      scores = gini_index.gini_index (X,y)\n","      return scores\n","    fselector = SelectKBest(gini_index_fct, k = n_feature)\n","  elif fsel == \"_PT_\":\n","    def t_score_fct (X, y):\n","      scores = t_score.t_score (X,y)\n","      return scores\n","    fselector = SelectKBest(t_score_fct, k = n_feature)\n","  elif fsel == \"_IMC_\":\n","    def jmi_fct (X, y):\n","      scores = JMI.jmi (X,y)\n","      return scores\n","    fselector = SelectKBest(jmi_fct, k = n_feature)\n","  elif fsel == \"_MIM_\":\n","    def mim_fct (X, y):\n","      scores = MIM.mim (X,y)\n","      return scores\n","    fselector = SelectKBest(mim_fct, k = n_feature)\n","  elif fsel == \"_MRMR_\":\n","    def mrmr_fct (X, y):\n","      scores = MRMR.mrmr (X,y)\n","      return scores\n","    fselector = SelectKBest(mrmr_fct, k = n_feature)\n","  #Feature Selection method created in the experiment using with reference the code of Aydin.\n","  elif fsel ==  \"_PW_\":\n","    def wilcoxon_score_fct (X, y):\n","      scores_ = wilcoxon_score (X,y)\n","      scores = feature_ranking(scores_)\n","      return scores\n","    fselector = SelectKBest(wilcoxon_score_fct, k = n_feature)\n","  return fselector"]},{"cell_type":"markdown","metadata":{"id":"FdrkqBNwp_ci"},"source":["####**Algoritmo de seleccion de caracteristicas en la base de datos del cancer de mama**"]},{"cell_type":"markdown","source":["#####**Base de datos cancer de mama**"],"metadata":{"id":"ZC8U8Qw2H-iw"}},{"cell_type":"code","source":["#dataframe de las caracteristicas de las imagenes\n","X = pd.read_excel(\"/content/drive/MyDrive/TESIS/Experimento_Final/Base_de_datos/Imaging_Features.xlsx\")\n","\n","#toma del dataframe de duke \"Clinical_and_Other_Features\" y filtra solo las columnas de los receptores hormonales y la clasificacion de subtipo molecular.\n","df_clinic = pd.read_excel(\"/content/drive/MyDrive/TESIS/Experimento_Final/Base_de_datos/Clinical_and_Other_Features.xlsx\")\n","y = (df_clinic[['Patient Information',\"Tumor Characteristics\",'Unnamed: 24','Unnamed: 25', 'Unnamed: 26']]\n","                     .rename(columns=df_clinic.iloc[0])\n","                     .drop(1)\n","                     .iloc[1:]\n","                     .reset_index(drop=True))\n","df_base = X.merge(y, on=\"Patient ID\")\n","df_base"],"metadata":{"id":"y9mL2BhhPRBC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####**Algoritmo para cancer de mama**"],"metadata":{"id":"JYzB7hIxWPTA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2BVQ0onnjYW"},"outputs":[],"source":["def Algoritmo_seleccion_caracterisitcas(df_base,problemas_elegidos,fsel,Random_State,n_caracteristicas):\n","'''PRIMERA PARTE:\n","  El problema elegido tiene dos formas de análisis:\n","  - El primero está relacionado con el subtipo molecular del cáncer de mama, donde la columna en el data frame se denomina 'Mol Subtype', en la que encontramos 4 clases, correspondientes a los 4 subtipos moleculares. luminal A, B, HER2 y triple negativo. Para este experimento, trabajaremos con problemas binarios, comparando una clase con las otras tres.\n","  - El segundo está relacionado con el receptor hormonal, donde las columnas se definen como ER, PR y HER2. Para este caso solo hay dos clases, es decir, es positivo (0) o negativo (1).\n","  '''\n","\n","  if chosen_problems == \"luminal_A\" or \"luminal_B\" or \"her2\" or \"triple_negative\":\n","    df = df_base.drop([\"Patient ID\",\"ER\",\"PR\",\"HER2\"], axis=1) #del marco de datos original, las columnas indicadas se eliminan, dejando la columna \"subtipo molecular\" como objetivo\n","  \n","    #Transforma otros subtipos definidos como clase 1, donde la clase 0 corresponde al tipo seleccionado.\n","    if chosen_problems ==\"luminal_A\":\n","      df.loc[df['Mol Subtype'] == 2, 'Mol Subtype'] = 1\n","      df.loc[df['Mol Subtype'] == 3, 'Mol Subtype'] = 1\n","    elif chosen_problems ==\"luminal_B\":\n","      df.loc[df['Mol Subtype'] == 0, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 1, 'Mol Subtype'] = 0\n","      df.loc[df['Mol Subtype'] == 2, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 3, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 4, 'Mol Subtype'] = 1\n","    elif chosen_problems ==\"her2\":\n","      df.loc[df['Mol Subtype'] == 0, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 1, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 2, 'Mol Subtype'] = 0\n","      df.loc[df['Mol Subtype'] == 3, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 4, 'Mol Subtype'] = 1\n","    else:\n","      df.loc[df['Mol Subtype'] == 0, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 1, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 2, 'Mol Subtype'] = 4\n","      df.loc[df['Mol Subtype'] == 3, 'Mol Subtype'] = 0\n","      df.loc[df['Mol Subtype'] == 4, 'Mol Subtype'] = 1\n","    \n","    '''División Características y target, en las variables X e y respectivamente'''\n","    # # Para este marco de datos, el objetivo son las columnas  \"Mol Subtype\"\n","    y = df[\"Mol Subtype\"]\n","    X = df.drop([\"Mol Subtype\"], axis = 1)\n","  \n","'''SEGUNDA PARTE: PREPROCESAMIENTO DE DATOS'''\n","\n","'''Imputadora para completar valores faltantes'''\n","  #se usó SimpleImputer de las bibliotecas Sklearn.\n","  simp = SimpleImputer(strategy=\"mean\") # \"media\", luego reemplace los valores faltantes usando la media a lo largo de cada columna. Solo se puede utilizar con datos numéricos.\n","  X = pd.DataFrame(simp.fit_transform(X),columns = X.columns)\n","\n"," '''escalamiento de datos'''\n","  #se usó StandardScaler de las bibliotecas Sklearn.\n","  sscal = StandardScaler() #Estandarice las características eliminando la media y escalando a la varianza de la unidad.\n","  X = pd.DataFrame(sscal.fit_transform(X),columns = X.columns) \n","'''Dividir conjunto de datos en entrenamiento y prueba'''\n","  #se uso train_test_split of the libaries Sklearn.\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.15,random_state=Random_State)\n","\n","  '''Manejo de clases desbalanceadas'''\n","  #se utilizó sobremuestreo de las librerías imblearn.\n","  if over_sampling == \"RandomOverSampler\":\n","    ros = RandomOverSampler(random_state=0)\n","    X_train, y_train = ros.fit_resample(X_train, y_train) \n","\n","  \n","'''TERCERA PARTE: MÉTODO DE SELECCIÓN DE CARACTERÍSTICAS'''\n","\n","  '''Se aplica el método de selección de caractertisticas.'''\n","  fselector = metodos_seleccion_caracteristicas(fsel, n_caracteristicas) # funcion metodos de seleccion de caracteristicas\n","  start = time.time()  # inicia el temporalizador de funcion metodos de seleccion de caracteristicas\n","  with np.errstate(divide='ignore',invalid='ignore'):\n","    fselector.fit(X_train, y_train) #Se ejecuta la funcion de seleccion de caracteristicas\n","  end = time.time() # finaliza el temporalizador de funcion metodos de seleccion de caracteristicas\n","  times_fselector = str(end - start) #times_fselector, corresponde al tiempo de ejecución del método de selección de características\n","  \n","  '''creación de dataframes filtrados'''\n","  feature_idx = fselector.get_support() #devuelve el índice de las características seleccionadas del dataframe de datos original\n","  feature_names = X.columns[feature_idx] #devuelve el nombre de las características seleccionadas del dataframe de datos original\n","  X_train_fs = fselector.transform(X_train) #devuelve una matriz de solo las características seleccionadas del dataframe de datos original, que se usa para el entrenamiento\n","  X_test_fs = fselector.transform(X_test) #devuelve una matriz de solo las características seleccionadas del dataframe de datos original, usando para probar\n","\n","  '''''Se crea un nuevo dataframe de datos con las características seleccionadas que se usarán tanto para entrenamiento como para prueba. '''\n","\n","  feature_names_series = pd.Series(feature_names,copy=False,name =times_fselector) #series con los nombres de las características seleccionadas\n","  X_train_fs = pd.DataFrame(X_train_fs,columns=feature_names)\n","  y_train = pd.Series(data = y_train)\n","  X_test_fs = pd.DataFrame(X_test_fs,columns=feature_names)\n","  y_test = pd.Series(data = y_test)\n","\n","\n","  '''Guardar archivos en CSV en Google Drive'''\n","\n","  #guardar archivos en CSV\n","  feature_names_series.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/feature_names/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_Nombres_caracteristicas\"+fsel+str(n_caracteristicas)+\".csv\")\n","  X_train_fs.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/X_train/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_X_train\"+fsel+str(n_caracteristicas)+\".csv\")\n","  y_train.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/y_train/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_y_train\"+fsel+str(n_caracteristicas)+\".csv\")\n","  X_test_fs.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/X_test/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_X_test\"+fsel+str(n_caracteristicas)+\".csv\")\n","  y_test.to_csv(\"/content/drive/MyDrive/tesis/\"+ problemas_elegidos +\"/seleccion_caracteristicas/\"+fsel+\"/_\"+str(Random_State)+\"/y_test/\"+chosen_problems +\"_rs_\"+str(Random_State)+\"_y_test\"+fsel+str(n_caracteristicas)+\".csv\")"]},{"cell_type":"markdown","metadata":{"id":"oI7bymSmvA3E"},"source":["#**Aplicacion del experimento**"]},{"cell_type":"markdown","metadata":{"id":"16h19NldWS4O"},"source":["##**MIM, IMC**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLs7J2vNyClq"},"outputs":[],"source":["#selecciona los parametros de la funcion Algoritmo_seleccion_caracterisitcas\n","problemas_elegidos,fsel,Random_State = MIM_IMC()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aDZV5L51HhZ"},"outputs":[],"source":["#ejecucion del experimento\n","for i in range(len(n_feature)):\n","  Algoritmo_seleccion_caracterisitcas(df_base,problemas_elegidos,fsel,Random_State,n_caracteristicas[i])"]},{"cell_type":"markdown","metadata":{"id":"JGKA77qFcWZ5"},"source":["##**IG**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcmCDi_zcblP"},"outputs":[],"source":["#selecciona los parametros de la funcion Algoritmo_seleccion_caracterisitcas\n","problemas_elegidos,fsel,Random_State = IG()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN_V7cy-cblT"},"outputs":[],"source":["#ejecucion del experimento\n","for x in range(len(Random_State)):\n","  for i in range(len(n_feature)):\n","    Algoritmo_seleccion_caracterisitcas(df_base,problemas_elegidos,fsel,Random_State[x],n_caracteristicas[i]):"]},{"cell_type":"markdown","metadata":{"id":"z4s5KAj8i-hF"},"source":["##**IM_RELF_MRMR**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Rtm8u5pi-hH"},"outputs":[],"source":["#selecciona los parametros de la funcion Algoritmo_seleccion_caracterisitcas\n","problemas_elegidos,fsel,Random_State = IM_RELF_MRMR()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DEF9WWsNi-hL"},"outputs":[],"source":["#ejecucion del experimento\n","for x in range(len(Random_State)):\n","  for i in range(len(n_feature)):\n","    Algoritmo_seleccion_caracterisitcas(df_base,problemas_elegidos,fsel,Random_State[x],n_caracteristicas[i]):"]},{"cell_type":"markdown","metadata":{"id":"58AFY1y5q5Ql"},"source":["##**MF, PF, PT y PW**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DwKjatnSq5Qr"},"outputs":[],"source":["#selecciona los parametros de la funcion Algoritmo_seleccion_caracterisitcas\n","problemas_elegidos,fsel,Random_State = MF_PF_PT_PW()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zgZZhHPq5Qv"},"outputs":[],"source":["#ejecucion del experimento  \n","for y in range(len(chosen_problems)):\n","  for x in range(len(Random_State)):\n","    for i in range(len(n_feature)):\n","      Algoritmo_seleccion_caracterisitcas(df_base,problemas_elegidos[y],fsel,Random_State[x],n_caracteristicas[i]):"]}],"metadata":{"colab":{"collapsed_sections":["kOEZ1btk9MnI","LvovWkLYHPaq","DIqsmonxHkqK","wCKh38yxHsSG","EdLpMV0Aie7-","ZC8U8Qw2H-iw","JYzB7hIxWPTA","oI7bymSmvA3E","16h19NldWS4O","JGKA77qFcWZ5","z4s5KAj8i-hF"],"provenance":[{"file_id":"1d5tk8Gw8lpTaO8mTcpU5mLamAV3RTr0l","timestamp":1676132181415}],"authorship_tag":"ABX9TyN/ZNNP8WErgdANRjo62V24"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}